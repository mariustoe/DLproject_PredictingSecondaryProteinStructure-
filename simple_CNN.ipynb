{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple convolutional neural network (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the file directory to you own here:\n",
    "### Load data\n",
    "drive_path = 'C:/Users/augus/OneDrive - Danmarks Tekniske Universitet/Studiemappe/9. semester/Deep Learning/project/'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.functional import relu, elu, relu6, sigmoid, tanh, softmax\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import sklearn.model_selection as model_selection\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindata = pickle.load(open(drive_path+'train.pickle','rb'))\n",
    "\n",
    "X = traindata[0][:,:,0:20]\n",
    "y = traindata[0][:,:,57:65]\n",
    "CASP12data = pickle.load(open(drive_path+'Casp12Data.pickle','rb'))\n",
    "X_casp = CASP12data[0][:,:,0:20]\n",
    "y_casp = CASP12data[0][:,:,57:65]\n",
    "TS115data = pickle.load(open(drive_path+'TS115.pickle','rb'))\n",
    "X_TS115 = TS115data[0][:,:,0:20]\n",
    "y_TS115 = TS115data[0][:,:,57:65]\n",
    "CB513data = pickle.load(open(drive_path+'CB513.pickle','rb'))\n",
    "X_CB513 = CB513data[0][:,:,0:20]\n",
    "y_CB513 = CB513data[0][:,:,57:65]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding the \"artificial\" class created by the extrapolation of the sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if y.shape[2] == 8:\n",
    "    EPzeros = np.expand_dims(np.zeros((y.shape[1])),1)\n",
    "    EPzeros_casp = np.expand_dims(np.zeros((y_casp.shape[1])),1)\n",
    "    EPzeros_TS115 = np.expand_dims(np.zeros((y_TS115.shape[1])),1)\n",
    "    EPzeros_CB513 = np.expand_dims(np.zeros((y_CB513.shape[1])),1)\n",
    "    y_red = np.asarray([np.hstack((y[i],EPzeros)) for i in range(y.shape[0])])\n",
    "    y_casp = np.asarray([np.hstack((y_casp[i],EPzeros_casp)) for i in range(y_casp.shape[0])])\n",
    "    y_TS115 = np.asarray([np.hstack((y_TS115[i],EPzeros_TS115)) for i in range(y_TS115.shape[0])])\n",
    "    y_CB513 = np.asarray([np.hstack((y_CB513[i],EPzeros_CB513)) for i in range(y_CB513.shape[0])])\n",
    "    for i in range(y.shape[0]):\n",
    "        for j in range(y[i].shape[0]):\n",
    "            if np.all(y[i][j,:] == 0):\n",
    "                y[i][j,:][-1] = 1\n",
    "    for i in range(y_casp.shape[0]):\n",
    "        for j in range(y_casp[i].shape[0]):\n",
    "            if np.all(y_casp[i][j,:] == 0):\n",
    "                y_casp[i][j,:][-1] = 1\n",
    "    for i in range(y_TS115.shape[0]):\n",
    "        for j in range(y_TS115[i].shape[0]):\n",
    "            if np.all(y_TS115[i][j,:] == 0):\n",
    "                y_TS115[i][j,:][-1] = 1\n",
    "    for i in range(y_CB513.shape[0]):\n",
    "        for j in range(y_CB513[i].shape[0]):\n",
    "            if np.all(y_CB513[i][j,:] == 0):\n",
    "                y_CB513[i][j,:][-1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(X, dtype = torch.float)\n",
    "y = torch.tensor(y, dtype = torch.float).permute(0,2,1)\n",
    "X_casp = torch.tensor(X_casp,dtype = torch.float)\n",
    "y_casp = torch.tensor(y_casp,dtype=torch.float).permute(0,2,1)\n",
    "X_TS115 = torch.tensor(X_TS115,dtype=torch.float)\n",
    "y_TS115 = torch.tensor(y_TS115,dtype=torch.float).permute(0,2,1)\n",
    "X_CB513 = torch.tensor(X_CB513,dtype=torch.float)\n",
    "y_CB513 = torch.tensor(y_CB513,dtype=torch.float).permute(0,2,1)\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.data = X\n",
    "        self.targets = y\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "      x = self.data[index]\n",
    "      y = self.targets[index]\n",
    "      return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "      return len(self.data)\n",
    "\n",
    "batch_size = 65\n",
    "TrainLoader = DataLoader(MyDataset(X,y),batch_size=batch_size)\n",
    "CASPLoader = DataLoader(MyDataset(X_casp,y_casp),batch_size=3)\n",
    "TS115Loader = DataLoader(MyDataset(X_TS115,y_TS115),batch_size=batch_size)\n",
    "CB513Loader = DataLoader(MyDataset(X_CB513,y_CB513),batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channels = 20\n",
    "kernel_size_conv1 = 15\n",
    "padding_conv1 = 7\n",
    "stride_conv1 = 1\n",
    "kernel_size_conv2 = 9\n",
    "padding_conv2 = 4\n",
    "stride_conv2 = 1\n",
    "kernel_size_conv3 = 5\n",
    "padding_conv3 = 2\n",
    "stride_conv3 = 1\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        ''''''\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=channels,out_channels=25,kernel_size=kernel_size_conv1 , stride=stride_conv1, padding=padding_conv1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(25),\n",
    "            nn.Dropout(p=0.5))\n",
    "\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=25, out_channels=35, kernel_size=kernel_size_conv2, stride=stride_conv2, padding=padding_conv2),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(35),\n",
    "            nn.Dropout(p=0.5))\n",
    "\n",
    "        self.conv3 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=35,out_channels=40, kernel_size=kernel_size_conv3, stride=stride_conv3, padding=padding_conv3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(40),\n",
    "            nn.Dropout(p=0.5))\n",
    "\n",
    "        self.fc1_encode1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=40,out_channels=9,kernel_size=1,stride=1,padding=0,bias=True),\n",
    "            nn.BatchNorm1d(9)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.fc1_encode1(x)\n",
    "        return x\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining criterion and optimizer\n",
    "import torch.optim as optim\n",
    "\n",
    "def criterion(input, target):\n",
    "    labels = torch.argmax(target,2)\n",
    "    return nn.CrossEntropyLoss()(input, labels)\n",
    "\n",
    "# Adam optimizer\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001,betas=(0.85,0.95),weight_decay=1e-6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch = 100\n",
    "train_loss = []\n",
    "train_accuracy = []\n",
    "casp_loss = []\n",
    "casp_accuracy = []\n",
    "TS115_loss = []\n",
    "TS115_accuracy = []\n",
    "CB513_loss = []\n",
    "CB513_accuracy = []\n",
    "\n",
    "for epoch in range(num_epoch):  # loop over the dataset multiple times\n",
    "    print('Epoch ',epoch+1,' of ',num_epoch)\n",
    "    running_loss = 0.0\n",
    "    running_acc = 0.0\n",
    "    net.train()\n",
    "    print('Training net')\n",
    "    for data in TrainLoader:\n",
    "        # get the inputs\n",
    "        inputs, labels = data\n",
    "        # wrap them in Variable\n",
    "        inputs, labels = Variable(inputs.permute(0,2,1)), Variable(labels)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        running_acc += getAccuracy(outputs,labels)\n",
    "        loss = criterion(outputs,labels.permute(0,2,1))\n",
    "        loss.backward()\n",
    "        running_loss += loss.data.numpy()\n",
    "        optimizer.step()\n",
    "    train_loss.append(running_loss2/len(TrainLoader))\n",
    "    train_accuracy.append(running_acc/len(TrainLoader))\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "        print('Testing on CASP')\n",
    "        for data in CASPLoader:\n",
    "            inputs, labels = data\n",
    "            outputs = net(Variable(inputs.permute(0,2,1)))\n",
    "            loss = criterion(outputs,labels.permute(0,2,1))\n",
    "            running_acc += getAccuracy(outputs,labels)\n",
    "            running_loss += loss.data.numpy()\n",
    "        casp_loss.append(running_loss/len(CASPLoader))\n",
    "        casp_accuracy.append(running_acc/len(CASPLoader))\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "        print('Testing on TS115')\n",
    "        for data in TS115Loader:\n",
    "            inputs, labels = data\n",
    "            outputs = net(Variable(inputs.permute(0,2,1)))\n",
    "            loss = criterion(outputs,labels.permute(0,2,1))\n",
    "            running_acc += getAccuracy(outputs,labels)\n",
    "            running_loss += loss.data.numpy()\n",
    "        TS115_loss.append(running_loss/len(TS115Loader))\n",
    "        TS115_accuracy.append(running_acc/len(TS115Loader))\n",
    "        running_loss = 0.0\n",
    "        running_acc = 0.0\n",
    "        print('Testing on CB513')\n",
    "        for data in CB513Loader:\n",
    "            inputs, labels = data\n",
    "            outputs = net(Variable(inputs.permute(0,2,1)))\n",
    "            loss = criterion(outputs,labels.permute(0,2,1))\n",
    "            running_acc += getAccuracy(outputs,labels)\n",
    "            running_loss += loss.data.numpy()\n",
    "        CB513_loss.append(running_loss/len(CB513Loader))\n",
    "        CB513_accuracy.append(running_acc/len(CB513Loader))\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = list(range(1,num_epoch+1))\n",
    "fig, axs = plt.subplots(1, 2, constrained_layout=False)\n",
    "axs[0].plot(scale, train_loss,label='Train')\n",
    "axs[0].plot(scale, casp_loss,label='CASP12')\n",
    "axs[0].plot(scale, TS115_loss,label='TS115')\n",
    "axs[0].plot(scale, CB513_loss,label='CB513')\n",
    "axs[0].set_xlabel('Epochs')\n",
    "axs[0].set_ylabel('Loss')\n",
    "axs[0].legend(loc='upper right')\n",
    "axs[1].plot(scale, train_accuracy,label='Train')\n",
    "axs[1].plot(scale, casp_accuracy,label='CASP12')\n",
    "axs[1].plot(scale, TS115_accuracy,label='TS115')\n",
    "axs[1].plot(scale, CB513_accuracy,label='CB513')\n",
    "axs[1].set_xlabel('Epochs')\n",
    "axs[1].set_ylabel('Accuracy')\n",
    "axs[1].legend(loc='lower right')\n",
    "fig.suptitle('Loss and accuracy curves', fontsize=16,y=1.05)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
